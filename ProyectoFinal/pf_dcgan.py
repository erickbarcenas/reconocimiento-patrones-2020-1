# -*- coding: utf-8 -*-
"""PF - DCGAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KNm5xApEO4-hy4CK9gwHVfoJ4T4wfPxx

# Proyecto Final. Generación de imágenes tomográficas por medio de una DCGAN.

Reconocomiento de Patrones

Andrés González Flores
"""

from __future__ import print_function
import argparse
import os
import random
import torch
import torch.nn as nn
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.optim as optim
import torch.utils.data
import torchvision.datasets as dset
import torchvision.transforms as transforms
import torchvision.utils as vutils
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from IPython.display import HTML
import glob
import imageio
import codecs
import hashlib 
import time

# Set random seed for reproducibility
manualSeed = 999
#manualSeed = random.randint(1, 10000) # use if you want new results
print("Random Seed: ", manualSeed)
random.seed(manualSeed)
torch.manual_seed(manualSeed)

"""## Entradas

- **dataroot** - La ruta al dataset.
- **workers** - Número de trabajadores que cargaran los datos al DataLoader
- **batch_size** - Tamaño del batch (lote, conjunto). El artículo DCGAN usa un lote de datos de 128
- **image_size** - El tamaño de las imágenes. Aquí usaré imágenes de 64x64.
- **nc** - Número de canales de color.
- **nz** - Tamaño del vector latente.
- **ngf** - Profundidad de los mapas de caracteristicas propagados a través del generador.
- **ndf** - Profundidad de los mapas de caracteristicas propagados a través del discriminador.
- **num_epochs** - Número de épocas a iterar.
- **lr** - Tasa de aprendizaje. Según el artículo de DCGAN, este valor debe ser 0.0002.
- **beta1** - Hyperparámetro beta1 para los optimizadores Adam. Como se describe en el artículo, este valor debe ser 0.5.
- **ngpu** - Número de GPUs disponibles
"""

# Root directory for dataset
dataroot = "dataset"

# Number of workers for dataloader
workers = 4

# Batch size during training
batch_size = 128

# Spatial size of training images. All images will be resized to this
#   size using a transformer.
image_size = 64

# Number of channels in the training images. For color images this is 3
nc = 1

# Size of z latent vector (i.e. size of generator input)
nz = 100

# Size of feature maps in generator
ngf = 64

# Size of feature maps in discriminator
ndf = 64

# Number of training epochs
num_epochs = 1000

# Learning rate for optimizers
dlr = 0.00005 
glr = 0.0002 

# Beta1 hyperparam for Adam optimizers
beta1 = 0.5

# Number of GPUs available. Use 0 for CPU mode.
ngpu = 1

# Imágenes para animación gif
nimgif = 12

"""## Datos

En esta práctica imágenes de tomografías computarizadas de estudios de corazón. Son cortes coaxiales donde se aprecia el ventrículo izquierdo (más claro) y alrededor el ventrículo derecho. 

El conjunto de datos suma un total de 250 imágenes.
"""

# We can use an image folder dataset the way we have it setup.
# Create the dataset
dataset = dset.ImageFolder(root=dataroot,
                           transform=transforms.Compose([
                               transforms.Resize(image_size),
                               transforms.CenterCrop(image_size),
                               transforms.Grayscale(num_output_channels=1),
                               transforms.ToTensor(),
                               transforms.Normalize([0.5], [0.5]),
                           ]))

# Número de imágenes en el dataset
n_imgs = len(dataset.imgs)

# Create the dataloader
dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,
                                         shuffle=True, num_workers=workers)

# Decide which device we want to run on
device = torch.device("cuda:0" if (torch.cuda.is_available() and ngpu > 0) else "cpu")

# Para generar imágenes de muestra cuadradas
if batch_size<64:
    vector_cuad = [x**2 for x in range(1, 9)]
    indice = np.floor(np.sqrt(32)).astype(np.uint8)-1
    n_img_grid = vector_cuad[indice]
else:
    n_img_grid = 64

# Plot some training images
real_batch = next(iter(dataloader))
plt.figure(figsize=(8,8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:n_img_grid], padding=2, normalize=True).cpu(),(1,2,0)))
plt.show()

"""## Implementación

### Inicialización de pesos
Del artículo de DCGAN, los autores indican que los pesos deben ser inicializados aleatoreamente de una distribución Normal con media = 0 y desviación estándar = 0.02. La función weights_init function toma un modelo inicializado como entrada y reinicializa todas sus capas para que cumplan con este criterio. La función es aplicada a los modelos inmediatamente después de su inicialización.
"""

# custom weights initialization called on netG and netD
def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)

"""### Generator
El generador, G, esta diseñado para mapear el vector del espacio latente (z) a el espacio de los datos. Como la información se compone de imágenes, convertir z al espacio de los datos implica crear una imágen con tamaño 64x64. En práctica, esto se logra a través de una serie de convoluciones transpuestas, cada una de ella en pareja con una capa batch norm y una capa de activación ReLU. La salida del generador sirve de entrada para una función tanh, que hace que los valores queden en el intervalo \[−1,1\]. 

![Generador](https://github.com/gandresto/reconocimiento-patrones-2020-1/blob/master/ProyectoFinal/dcgan_generator.png?raw=1)

El código del generador se presenta a continuación:
"""

# Generator Code
class Generator(nn.Module):
    def __init__(self, ngpu):
        super(Generator, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            # input is Z, going into a convolution
            nn.ConvTranspose2d(in_channels = nz, 
                               out_channels = ngf * 8, 
                               kernel_size = 4, 
                               stride = 1, 
                               padding = 0, 
                               bias=False),
            nn.BatchNorm2d(ngf * 8),
            nn.ReLU(True),
            # state size. (ngf*8) x 4 x 4
            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),
            # state size. (ngf*4) x 8 x 8
            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),
            # state size. (ngf*2) x 16 x 16
            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf),
            nn.ReLU(True),
            # state size. (ngf) x 32 x 32
            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),
            nn.Tanh()
            # state size. (nc) x 64 x 64
        )

    def forward(self, input):
        return self.main(input)

"""Ahora inicializamos el generador junto con sus pesos."""

# Create the generator
netG = Generator(ngpu).to(device)

# Handle multi-gpu if desired
if (device.type == 'cuda') and (ngpu > 1):
    netG = nn.DataParallel(netG, list(range(ngpu)))

# Apply the weights_init function to randomly initialize all weights
#  to mean=0, stdev=0.2.
netG.apply(weights_init)

# Print the model
print(netG)

"""### Discriminator

El discriminador, D, es una red de clasificación binaria que toma una imágen como entrada y tiene como salida una probabilidad de que dicha imagen haya sido real. Aquí, el discriminador toma una imagen de 64x64 y la pasa a través de capas Conv2d, BatchNorm2d, y LeakyReLU, y tiene como salida la probabilidad final a través de una función de activación Sigmoide. El artículo de DCGAN menciona que es buena práctica usar convoluciones con saltos (strided conv) en lugar de pooling para decimar, ya que deja a la red aprender su propia función de decimación.

Código del Discriminador:
"""

class Discriminator(nn.Module):
    def __init__(self, ngpu):
        super(Discriminator, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            # input is (nc) x 64 x 64
            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf) x 32 x 32
            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*2) x 16 x 16
            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*4) x 8 x 8
            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 8),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*8) x 4 x 4
            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, input):
        return self.main(input)

"""Creamos el discriminador y lo inicializamos con sus pesos."""

# Create the Discriminator
netD = Discriminator(ngpu).to(device)

# Handle multi-gpu if desired
if (device.type == 'cuda') and (ngpu > 1):
    netD = nn.DataParallel(netD, list(range(ngpu)))

# Apply the weights_init function to randomly initialize all weights
#  to mean=0, stdev=0.2.
netD.apply(weights_init)

# Print the model
print(netD)

"""### Funciones de Costo y Optimizadores

Con G y D configurados, podemos especificar cómo es que aprenderán a través de las funciones de coste y de los optimizadores. Se usará la función de coste de Entropía Binaria Curzada (BCELoss en pytorch):

![BCELoss.png](https://raw.githubusercontent.com/gandresto/reconocimiento-patrones-2020-1/master/ProyectoFinal/BCELoss.PNG)

Notamos cómo es que esta función ya nos proporciona los cálculos que necesitamos de la función objetivo (por ejemplo log(D(x)) y log(1−D(G(z)))). Podemos especificar qué parte de la función BCE usar con cambiar y. 

Después, definimos las etiquetas: 1 para los datos reales y 0 para los hechos por el generador. Por último definimos dos optimizadores, uno para D y otro para G. El artículo especifica usar una tasa de aprendizaje de 0.0002 y Beta1 de 0.5 para ambos optimizadores. 

Para observar el progreso, cada ciertas iteraciones muestro un conjunto de imágenes generadas de un conjunto de vectores con ruido gaussiano pasadas a través del generador.
"""

# Initialize BCELoss function
criterion = nn.BCELoss()

# Create batch of latent vectors that we will use to visualize
#  the progression of the generator
fixed_noise = torch.randn(64, nz, 1, 1, device=device)

# Establish convention for real and fake labels during training
real_label = 1
fake_label = 0

# Setup Adam optimizers for both G and D
optimizerD = optim.Adam(netD.parameters(), lr=dlr, betas=(beta1, 0.999))
optimizerG = optim.Adam(netG.parameters(), lr=glr, betas=(beta1, 0.999))

"""### Entrenamiento

Finalmente, ahora que tenemos todas las partes del framework de una GAN, podemos entrenarla. Entrenar GANs es una especie de arte, ya que utilizar hiperparámetros incorrectos puede llevar a colapso de modo con poca explicación de qué salió mal. Aquí, se sigue detenidamente el algoritmo de Goodfellow, respetando algunas de las mejores prácticas sugeridas en ganhacks. Es decir, se construirán diferentes mini-batches para imágenes falsas y reales, se ajustará la función objetivo de G para que maximice logD(G(z)). El entrenamiento se divide en dos partes. La Primera Parte actualiza el Discriminador y la Segunda Parte el Generador.

#### Primera Parte - Entrenar al Discriminador

Recordando, el objetivo del discriminador es maximizar la probabilidad de clasificar correctamente una entrada dada como real o falsa. En práctica, queremos maximizar log(D(x))+log(1−D(G(z))). Debido a la sugerencia de separar dos mini-batches de ganhacks, calculamos esto en dos pasos. Primero construiremos un barch de muestras reales del conjunto de entrenamiento, los pasaremos a través la red D, calculamos el costo (log(D(x))), luego calculamos los gradientes. En segunda instancia, construiremos un batch con muestras falsas, las pasamos a través de la red D, calculamos el costo (log(1−D(G(z)))), y acumulamos los gradientes. Ahora, ya que tenemos los costes de ambos batches, podemos llamar un paso del optimizador del Discriminador.

#### Segunda Parte - Entrenar al Generador

Como lo dice el artículo original, queremos entrenar al Generador minimizando log(1−D(G(z))) en un esfuerzo por generar mejores imágenes falsas. Como se mencionó, Goodfellow mostró que esto no produce suficientes gradientes, especialmente en etapas tempranas de entrenamiento. Como una solución, en lugar a esllo, buscamos maximizar log(D(G(z))). En el código, logramos esto al clasificar la salida del Generador de la Primera Parte con el Discriminador, calcular el coste de G usando etiquetas reales como GT, calculamos los gradientes de G y, finalmente, actualizando los parámetros de G con un paso del optimizador. Parecería contrainituitivo usar las etiquetas reales como etiquetas de GT para la función de coste, pero esto nos permite usar la parte log(x) del BCELoss (en lugar de la parte log(1-x)) que es exactamente lo que buscamos.

FInalmente, añadimos algo de reporte estadístico y al final de cada época, mandamos ruido fijo a través del generador para visualizar el progreso del entrenamiento de G. Las estadísticas de entrenamiento reportadas son:

- Loss_D - el coste del discriminador, calculado como la suma de costes de los batches reales y falsos (log(D(x))+log(D(G(z)))).
- Loss_G - el coste del generador, calculado con log(D(G(z)))
- D(x) - la salida promedio (a través del batch) del discriminador para todos los batches reales. Esto debería iniciar cercano a 1 y luego, teóricamente, converger a 0.5.
- D(G(z)) - la salida promedio del discriminador para todos los batches falsos. El primero número es antes de que D sea actualizado y el segundo número es luego de que D sea actualizado. Estos valores deberían iniciar cercanos a 0 y luego converger a 0.5 conforme G se vuelve mejor.
"""

# Commented out IPython magic to ensure Python compatibility.
# Training Loop

# Lists to keep track of progress
img_list = []
G_losses = []
D_losses = []
iters = 0

# Guardar imágenes cada i iteraciones
modulo = np.ceil(num_epochs*np.round(n_imgs/batch_size)/(nimgif-1))

print("Starting Training Loop...")
# For each epoch
start = time.time()
for epoch in range(num_epochs):
    # For each batch in the dataloader
    for i, data in enumerate(dataloader, 0):

        ############################
        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))
        ###########################
        ## Train with all-real batch
        netD.zero_grad()
        # Format batch
        real_cpu = data[0].to(device)
        b_size = real_cpu.size(0)
        label = torch.full((b_size,), real_label, device=device)
        # Forward pass real batch through D
        output = netD(real_cpu).view(-1)
        # Calculate loss on all-real batch
        errD_real = criterion(output, label)
        # Calculate gradients for D in backward pass
        errD_real.backward()
        D_x = output.mean().item()

        ## Train with all-fake batch
        # Generate batch of latent vectors
        noise = torch.randn(b_size, nz, 1, 1, device=device)
        # Generate fake image batch with G
        fake = netG(noise)
        label.fill_(fake_label)
        # Classify all fake batch with D
        output = netD(fake.detach()).view(-1)
        # Calculate D's loss on the all-fake batch
        errD_fake = criterion(output, label)
        # Calculate the gradients for this batch
        errD_fake.backward()
        D_G_z1 = output.mean().item()
        # Add the gradients from the all-real and all-fake batches
        errD = errD_real + errD_fake
        # Update D
        optimizerD.step()

        ############################
        # (2) Update G network: maximize log(D(G(z)))
        ###########################
        netG.zero_grad()
        label.fill_(real_label)  # fake labels are real for generator cost
        # Since we just updated D, perform another forward pass of all-fake batch through D
        output = netD(fake).view(-1)
        # Calculate G's loss based on this output
        errG = criterion(output, label)
        # Calculate gradients for G
        errG.backward()
        D_G_z2 = output.mean().item()
        # Update G
        optimizerG.step()

        # Output training stats
        if i % 50 == 0:
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
#                   % (epoch, num_epochs, i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save Losses for plotting later
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on fixed_noise
        if (iters % modulo == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))

        iters += 1
        
end = time.time()
t_entrenamiento = end-start

"""**Tiempo de entrenamiento**"""

(t_ent, seg) = divmod(np.round(t_entrenamiento), 60) 
(t_ent, minut) = divmod(t_ent, 60)
(t_ent, horas) = divmod(t_ent, 60) 
(t_ent, dias) = divmod(t_ent, 24) 
print('Tiempo de entrenamiento: ', end='')
if dias > 0:
    print('%d día(s), ' % dias, end='')
if horas > 0:
    print('%d hora(s), ' % horas, end='')
if minut > 0:
    print('%d minuto(s), ' % minut, end='')
print('%d segundo(s)' % seg)

"""## Resultados

Finalmente, verificamos cómo fue desempeñándose la red. Aquí, veremos tres resultados diferentes. Primero, veremos cómo cambiaron los costes de D y G durante el entrenamiento. Después, visualizaremos la salida de G con fixed_noise como entrada en cada época. Y por último, veremos la comparación entre un batch de datos reales y uno de datos falsos de G.

**Coste vs iteraciones de entrenamiento** 

Aquí veremos una gráfica de los costes de D y G vs iteraciones de entrenamiento.
"""

plt.figure(figsize=(10,5))
plt.title("Coste del Generador y el Discriminador Durante el Entrenamiento")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iteraciones")
plt.ylabel("Coste")
plt.legend()
plt.show()

"""**Visualizando el progreso de G**

Al salvar un batch falso cada ciertas iteraciones, podemos visualizar el progreso de entrenamiento en G con una anumación.
"""

#%%capture
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True, cmap='gray')] for i in img_list]
ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)

HTML(ani.to_jshtml())

"""**Guardo la imagen en formato gif**"""

gif_file = 'resultado.gif'

imagenes = []
imagenes_gif = []
for img in img_list:
    img = np.dstack((img.numpy()*256).astype(np.uint8))
    imagenes.append(img)
    for j in range(7):
        imagenes_gif.append(img)
                    
imagenes  = np.array(imagenes)
#imagenes_gif  = np.array(imagenes)

imageio.mimsave(gif_file, imagenes_gif)

"""**Guardando resultado en formato avi**"""

import cv2

video_file = 'resultado.avi'

height, width, layers = imagenes[0].shape
size = (width,height)

out = cv2.VideoWriter(video_file,cv2.VideoWriter_fourcc(*'DIVX'), 15, size)
 
for i in range(len(imagenes)):
    for j in range(15):
        out.write(imagenes[i])
out.release()

"""**Real Images vs. Fake Images**

Finally, lets take a look at some real images and fake images side by side.
"""

# Grab a batch of real images from the dataloader
real_batch = next(iter(dataloader))

# Plot the real images
fig = plt.figure(figsize=(15,15))
plt.subplot(1,2,1)
plt.axis("off")
plt.title("Imágenes Reales")
plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))

# Plot the fake images from the last epoch
plt.subplot(1,2,2)
plt.axis("off")
plt.title("Imágenes Falsas")
plt.imshow(np.transpose(img_list[-1],(1,2,0)))
plt.show()

# Guardar la comparación
comp_file = 'real vs fake.png'
fig.savefig(comp_file)

"""**Guardando hyperparámetros**"""

# Función hash para nombres de folders únicos
def md5(fname):
    hash_md5 = hashlib.md5()
    with open(fname, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_md5.update(chunk)
    return hash_md5.hexdigest()

md_file = 'hyperparametros.md'

with codecs.open(md_file, 'w', 'utf-8') as archivo:
    archivo.write('# Parámetros usados para obtener este resultado\n\n')
    archivo.write('- manualSeed = %d\n' % manualSeed)
    archivo.write('- batch_size = %d\n' % batch_size)
    archivo.write('- image_size = %d\n' % image_size)
    archivo.write('- nz = %d\n' % nz)
    archivo.write('- ngf = %d\n' % ngf)
    archivo.write('- ndf = %d\n' % ndf)
    archivo.write('- num_epochs = %d\n' % num_epochs)
    #archivo.write('- lr = %d\n' % lr)
    archivo.write('- dlr = %f\n' % dlr)
    archivo.write('- glr = %f\n' % glr)
    archivo.write('- beta1 = %f\n' % beta1)

# Creo folder con nombre único basado en los hiperparámetros
folder = md5(md_file)
try:
    os.mkdir('./resultados/'+folder)
    print('Folder creado')
except FileExistsError:
    print('El folder ya existe')

"""**Guardo diccionarios de estado**"""

f_models = 'checkpoint.pth' 
torch.save({
            'D_state_dict': netD.state_dict(),
            'G_state_dict': netG.state_dict(),
            #'optimizerD_state_dict': optimizerD.state_dict(),
            #'optimizerG_state_dict': optimizerG.state_dict(),
            }, f_models)

"""**Muevo todos los archivos al folder creado**"""

f_list = [md_file,gif_file,video_file,comp_file, f_models]
for fname in f_list:    
    try:    
        os.rename(fname, './resultados/'+folder+'/'+fname)
    except FileExistsError as fexerr:
        print("FileExistsError: {0}".format(fexerr))
    except PermissionError as perr:
        print("PermissionError: {0}".format(perr))
    except FileNotFoundError as fnferr:
        print("FileNotFoundError: {0}".format(fnferr))